{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UZ_utils import *\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1, task (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = imread(\".\\\\images\\\\umbrellas.jpg\")\n",
    "imshow(I)\n",
    "height, width, channels = I.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1, task (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_gray = np.sum(I, axis=2) / 3\n",
    "plt.title(\"Excercise 1, task (b)\")\n",
    "plt.imshow(I_gray, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1, task (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_rectangle_monochannel(I, x: tuple, y: tuple, channel: int):\n",
    "    return_array = I[x[0]:x[1], y[0]:y[1], channel]\n",
    "    return return_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Excercise 1, task (c)\")\n",
    "I_red = cut_rectangle_monochannel(I, (130, 260), (240, 450), 0)\n",
    "plt.imshow(I_red)\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(I_red, cmap='gray')\n",
    "\n",
    "I_green = cut_rectangle_monochannel(I, (130, 260), (240, 450), 1)\n",
    "I_blue = cut_rectangle_monochannel(I, (130, 260), (240, 450), 2)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(I_green)\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(I_blue)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1, task (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_subimage_float_inplace(I, x: tuple, y: tuple):\n",
    "    # All channels there are get inverted.\n",
    "    I[x[0]:x[1], y[0]:y[1], :] = 1 - I[x[0]:x[1], y[0]:y[1], :]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_subimage_float_inplace(I, (130, 260), (240, 450))\n",
    "plt.clf()\n",
    "plt.imshow(I)\n",
    "plt.title(\"Excercise 1, task (d)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1, task (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_gray_reduced = I_gray * 0.3\n",
    "plt.clf()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Excercise 1, task (e): failed example\")\n",
    "plt.imshow(I_gray, cmap='gray')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(I_gray_reduced, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Excercise 1, task (e): successful example\")\n",
    "plt.imshow(I_gray, vmin=0, vmax=1, cmap='gray')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(I_gray_reduced, vmin=0, vmax=1, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2, task (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treshold_mask(I_gray, treshold):\n",
    "    I_mask = np.copy(I_gray)\n",
    "    I_mask[I_gray < treshold] = 0\n",
    "    I_mask[I_gray >= treshold] = 1\n",
    "\n",
    "    return I_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_bird = imread(\".\\\\images\\\\bird.jpg\")\n",
    "I_bird_gray = np.sum(I_bird, axis=2) / 3\n",
    "treshold = 0.3\n",
    "I_bird_mask = treshold_mask(I_bird_gray, treshold)\n",
    "\n",
    "plt.clf()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Excercise 2, task (a)\")\n",
    "plt.imshow(I_bird)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(I_bird_mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2, task (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The histograms are usually normalized by dividing the result by the sum of all cells. Why is that?\n",
    "This allows us to compare histograms with different numbers of pixels. Moreover, most libraries use algorithms which assume the histogram is normalised.\n",
    "A normalised histogram is also already a probability distribution of the pixels' values, which can be useful in certain applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myhist(I_gray, num_of_bins):\n",
    "    \n",
    "    # H[0] will hold the x value of the bar.\n",
    "    # H[1] will hold the normalized counts for each bar (their heights).\n",
    "    H = np.zeros((2, num_of_bins))\n",
    "    \n",
    "    pixel_vals = np.reshape(I_gray, -1)\n",
    "    min = 0\n",
    "    max = 1\n",
    "    value_span = max - min\n",
    "\n",
    "    divider = 1/num_of_bins\n",
    "    pixel_vals = pixel_vals / divider\n",
    "    pixel_vals = (np.floor(pixel_vals)).astype(int)\n",
    "    # We've converted each pixel value to an integer k, where:\n",
    "    # pixel value = k * divider + something less than a divider.\n",
    "    # And k is also the index of the bin this pixel belonds to.\n",
    "\n",
    "\n",
    "    # we need to add the divider/2 to get the mean of the column correctly,\n",
    "    # not the left side (floored) of the column\n",
    "    bar_values_of_pixels = [min + divider * i + divider/2 for i in range(0, num_of_bins)]\n",
    "    H[0][:] = np.array(bar_values_of_pixels)\n",
    "\n",
    "\n",
    "    unique_vals, counts = np.unique(pixel_vals, return_counts=True)\n",
    "    for i in range(len(unique_vals)):\n",
    "        if unique_vals[i] == num_of_bins:\n",
    "        # just for the chance that it's exactly equal to the maximum\n",
    "            H[1][num_of_bins-1] += counts[i]\n",
    "        else:\n",
    "            H[1][unique_vals[i]] += counts[i]\n",
    "\n",
    "    H[1] = H[1] / np.sum(H[1])\n",
    "    return H\n",
    "\n",
    "def plot_histogram(histogram, title=\"\"):\n",
    "    plt.clf()\n",
    "    \n",
    "    H = histogram\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title(title)\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_num_of_bins = 150\n",
    "bird_histogram = myhist(I_bird_gray, desired_num_of_bins)\n",
    "plot_histogram(bird_histogram, \"Excercise 2, task (b)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2, task (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why would you use different color maps?\n",
    "Using only a grayscale colormap allows us to only work with 256 values. The differences between neigbouring values of what we are trying to show will therefore not have as much diffence in their visual representation.\n",
    "But if we use colours in our color map we are roking with 256^3 values. This allows us to display the differences in the values we are plotting much more finely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myhist_dynamic(I_gray, num_of_bins):\n",
    "\n",
    "    # H[0] will hold the x value of the bar.\n",
    "    # H[1] will hold the normalized counts for each bar (their heights).\n",
    "    H = np.zeros((2, num_of_bins))\n",
    "    \n",
    "\n",
    "\n",
    "    pixel_vals = np.reshape(I_gray, -1)\n",
    "    max = pixel_vals.max()\n",
    "    min = pixel_vals.min()\n",
    "    value_span = max - min\n",
    "\n",
    "    divider = value_span/num_of_bins\n",
    "    pixel_vals = pixel_vals-min\n",
    "    pixel_vals = pixel_vals / divider\n",
    "    pixel_vals = (np.floor(pixel_vals)).astype(int)\n",
    "    # We've converted each pixel value to an integer k, where:\n",
    "    # pixel value = k * divider + something less than a divider.\n",
    "    # And k is also the index of the bin this pixel belonds to.\n",
    "    \n",
    "\n",
    "    # we need to add the divider/2 to get the mean of the column correctly,\n",
    "    # not the left side (floored) of the column\n",
    "    bar_values_of_pixels = [min + divider * i + divider/2 for i in range(0, num_of_bins)]\n",
    "    H[0][:] = np.array(bar_values_of_pixels)\n",
    "    \n",
    "\n",
    "    unique_vals, counts = np.unique(pixel_vals, return_counts=True)\n",
    "    for i in range(len(unique_vals)):\n",
    "    # just for the chance that it's exactly equal to the maximum\n",
    "        if unique_vals[i] == num_of_bins:\n",
    "            H[1][num_of_bins-1] += counts[i]\n",
    "        else:\n",
    "            H[1][unique_vals[i]] += counts[i]\n",
    "\n",
    "    # normalization of the counts\n",
    "    H[1] = H[1] / np.sum(H[1])\n",
    "\n",
    "    return H\n",
    "\n",
    "def plot_both_types_of_histograms(I_gray, num_of_bins = 100, title=\"\"):\n",
    "    plt.clf()\n",
    "    \n",
    "    H = myhist(I_gray, num_of_bins)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    \n",
    "    plt.title(title)\n",
    "    print(\"Both types of histograms. Upper historgram is myhist, lower one is myhist_dynamic.\")\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "    \n",
    "    H = myhist_dynamic(I_gray, num_of_bins)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "    plt.show()\n",
    "\n",
    "def show_difference_of_dynamic_myhist(title=\"\"):\n",
    "    I = np.arange(0.4, 0.7, 0.001)\n",
    "    num_of_bins = 100\n",
    "\n",
    "    plt.clf()\n",
    "\n",
    "    H = myhist(I, num_of_bins)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(title)\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "\n",
    "    H = myhist_dynamic(I, num_of_bins)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_both_types_of_histograms(I_bird_gray, 100, \"Excercise 2, task (c): bird.jpg\")\n",
    "\n",
    "I_bird = imread(\".\\\\images\\\\bird.jpg\")\n",
    "I_bird_gray = np.sum(I_bird, axis=2) / 3\n",
    "\n",
    "I_bird_gray_demaxed = I_bird_gray[I_bird_gray < 0.3] \n",
    "plot_both_types_of_histograms(I_bird_gray_demaxed, 100, \"Excercise 2, task (c): bird.jpg, maxed at 0.3\")\n",
    "\n",
    "I_bird_gray_demaxed = I_bird_gray * 0.3\n",
    "plot_both_types_of_histograms(I_bird_gray_demaxed, 100, \"Excercise 2, task (c): bird.jpg scaled by 0.3\")\n",
    "show_difference_of_dynamic_myhist(\"Excercise 2, task (c): made up image example for myhist and myhist_dynamic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2, task (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is inverting a grayscale value defined?\n",
    "Grayscale_val_inverted = 1 - grayscale_val, assuming grayscale is represented with a floating point number on the interval [0, 1].\n",
    "In 8-bit representation it would be:\n",
    "Grayscale_val_inverted = 255 - grayscale_val,\n",
    "since 255 is the highest number the value can reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result interpretation\n",
    "When the number of bins is 100 we seem to already get an accurate shape of what the images probability distribution is. With more bins we start to get nearby bins that have hugely different probabilities, possibly because of random chance. Also possibly due to the number of bins not equaling the total possible number of values, therefore some bins might be capturing 2 pixel values, while other pins only capture 1.\n",
    "So if we are making a probability distribution, especially if we aren't going to be using the exact number of bins as there are possible pixel values, we might get a better result with a smaller, yet not extremely small number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_myhist_for_3_images(list_of_3_gray_images: list, num_of_bins):\n",
    "    plt.clf()\n",
    "    \n",
    "    image_list = list_of_3_gray_images\n",
    "    \n",
    "    H = myhist(image_list[0], num_of_bins)\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title(\"Excercise 2, task (d): num_of_bins = \" + str(num_of_bins))\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "    \n",
    "    H = myhist(image_list[1], num_of_bins)\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "    \n",
    "    H = myhist(image_list[2], num_of_bins)\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.bar(H[0], H[1], align='center', width=((H[0][1]-H[0][0])/1.2))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I1 = np.sum(imread(\".\\\\moje_slike\\\\temna.jpg\"), axis=2) / 3\n",
    "I2 = np.sum(imread(\".\\\\moje_slike\\\\srednja.jpg\"), axis=2) / 3\n",
    "I3 = np.sum(imread(\".\\\\moje_slike\\\\svetla.jpg\"), axis=2) / 3\n",
    "\n",
    "for num_of_bins in range(30, 256, 70):\n",
    "    plot_myhist_for_3_images([I1, I2, I3], num_of_bins)\n",
    "\n",
    "I1 = np.sum(imread(\".\\\\moje_slike\\\\temna_cedevita.jpg\"), axis=2) / 3\n",
    "I2 = np.sum(imread(\".\\\\moje_slike\\\\srednja_cedevita.jpg\"), axis=2) / 3\n",
    "I3 = np.sum(imread(\".\\\\moje_slike\\\\svetla_cedevita.jpg\"), axis=2) / 3\n",
    "\n",
    "for num_of_bins in range(30, 256, 70):\n",
    "    plot_myhist_for_3_images([I1, I2, I3], num_of_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2, task (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu_get_bin(H):\n",
    "    # Returns the index of the first bin on the right side of the divide.\n",
    "    # Returns in the range 1 to (num_of_bins-1).\n",
    "    \n",
    "    num_of_bins = H.shape[1]\n",
    "    max_var_between = -1\n",
    "    best_T = -1\n",
    "    for T in range(1, num_of_bins):\n",
    "\n",
    "        background_percentage = np.sum(H[1][0:T])\n",
    "        foreground_percentage = np.sum(H[1][T:])\n",
    "\n",
    "        background_weighted_values = H[0][0:T] * H[1][0:T]\n",
    "        foreground_weighted_values = H[0][T:] * H[1][T:]\n",
    "\n",
    "        background_mean = np.sum(background_weighted_values)/background_percentage\n",
    "        foreground_mean = np.sum(foreground_weighted_values)/foreground_percentage\n",
    "\n",
    "\n",
    "        var_between = background_percentage * foreground_percentage * (background_mean - foreground_mean)**2\n",
    "        \n",
    "        if var_between > max_var_between:\n",
    "            max_var_between = var_between\n",
    "            best_T = T\n",
    "    \n",
    "            \n",
    "    return best_T\n",
    "\n",
    "def otsu_get_bin2(H, num):\n",
    "    \n",
    "    num_of_bins = H.shape[1]\n",
    "    max_var_between = -1000\n",
    "    best_T = -1\n",
    "\n",
    "    # denormalizing H\n",
    "    H[1] = H[1]*num\n",
    "\n",
    "    for T in range(1, num_of_bins):\n",
    "\n",
    "\n",
    "        # These are the number of pixels in the background / all pixels and likewise for foreground. \n",
    "        background_numerus = np.sum(H[1][0:T]) # / T\n",
    "        foreground_numerus = np.sum(H[1][T:]) # / (num-T)\n",
    "\n",
    "        background_percentage = background_percentage / num\n",
    "        foreground_percentage = foreground_numerus / num\n",
    "\n",
    "        background_weighted_values = H[0][0:T] * H[1][0:T]\n",
    "        foreground_weighted_values = H[0][T:] * H[1][T:]\n",
    "\n",
    "        background_mean = np.sum(background_weighted_values)/background_numerus\n",
    "        foreground_mean = np.sum(foreground_weighted_values)/foreground_numerus\n",
    "\n",
    "\n",
    "\n",
    "        var_between = background_percentage * foreground_percentage * (background_mean - foreground_mean)**2\n",
    "        \n",
    "        if var_between > max_var_between:\n",
    "            max_var_between = var_between\n",
    "            best_T = T\n",
    "    \n",
    "    return best_T\n",
    "\n",
    "def otsu_treshold(I_gray, num_of_bins):\n",
    "    H = myhist_dynamic(I_gray, num_of_bins)\n",
    "    bin = otsu_get_bin(H)\n",
    "    # bin = otsu_get_bin2(H, I_gray.size)\n",
    "    \n",
    "    # this dinds the value that separates the bars correctly.\n",
    "    # It averages the centre values of the bars between which the treshold is.\n",
    "    # We can see this as: (left_upper_bar_val+divider/2 + left_upper_bar_val-divider/2)/2\n",
    "    treshold = (H[0][bin] + H[0][bin-1])/2\n",
    "\n",
    "    return treshold\n",
    "\n",
    "def otsu_showcase(num_of_bins=256):\n",
    "    \n",
    "    img_names = [\"umbrellas.jpg\", \"bird.jpg\", \"candy.jpg\", \"eagle.jpg\", \"mask.png\"]\n",
    "    for name in img_names:\n",
    "        path = \".\\\\images\\\\\" + name\n",
    "        I = imread(path)\n",
    "        I_gray = np.sum(I, axis=2) / 3\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title(\"Excercise 2, task (e): \" + name)\n",
    "        plt.imshow(I_gray, cmap='gray')\n",
    "        \n",
    "        I_mask = treshold_mask(I_gray, otsu_treshold(I_gray, num_of_bins))\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.imshow(I_mask, cmap='gray')\n",
    "\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otsu_showcase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the results, which order of erosion and dilation operations produces opening and which closing?\n",
    "First applying dilation, then erosion, produces closing, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion(I_gray, n=5):\n",
    "    SE = np.ones((n,n)) # create a square structuring element\n",
    "    I_eroded = cv2.erode(I_gray, SE)\n",
    "    return I_eroded\n",
    "\n",
    "def dilation(I_gray, n=5):\n",
    "    SE = np.ones((n,n)) # create a square structuring element\n",
    "    I_dilated = cv2.dilate(I_gray, SE)\n",
    "    return I_dilated\n",
    "\n",
    "def opening(I_gray, n=5):\n",
    "    I_opened = dilation(erosion(I_gray, n), n)\n",
    "    return I_opened\n",
    "\n",
    "def closing(I_gray, n=5):\n",
    "    I_closed = erosion(dilation(I_gray, n), n)\n",
    "    return I_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_maskJpeg = imread(\".\\\\images\\\\mask.png\")\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"E3, task (a). Basic image:\")\n",
    "plt.imshow(I_maskJpeg, cmap='gray')\n",
    "\n",
    "I_maskJpeg_gray = np.sum(I_maskJpeg, axis=2) / 3\n",
    "plt.subplot(2,2,2)\n",
    "plt.title(\"Gray image:\")\n",
    "plt.imshow(I_maskJpeg_gray, cmap='gray')\n",
    "\n",
    "I_maskJpeg_dilated = dilation(I_maskJpeg_gray)\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(\"Dilated image:\")\n",
    "plt.imshow(I_maskJpeg_dilated, cmap='gray')\n",
    "\n",
    "I_maskJpeg_eroded = erosion(I_maskJpeg_gray)\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(\"Eroded image:\")\n",
    "plt.imshow(I_maskJpeg_eroded, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3, task (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erosion_ellipse(I_gray, n1=5, n2=5):\n",
    "    SE = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(n1,n2))\n",
    "    I_eroded = cv2.erode(I_gray, SE)\n",
    "    return I_eroded\n",
    "\n",
    "def dilation_ellipse(I_gray, n1=5, n2=5):\n",
    "    SE = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(n1,n2))\n",
    "    I_dilated = cv2.dilate(I_gray, SE)\n",
    "    return I_dilated\n",
    "\n",
    "def opening_ellipse(I_gray, n1=5, n2=5):\n",
    "    I_opened = dilation_ellipse(erosion_ellipse(I_gray, n1, n2), n1, n2)\n",
    "    return I_opened\n",
    "\n",
    "def closing_ellipse(I_gray, n1=5, n2=5):\n",
    "    I_closed = erosion_ellipse(dilation_ellipse(I_gray, n1, n2), n1, n2)\n",
    "    return I_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_bird = imread(\".\\\\images\\\\bird.jpg\")\n",
    "I_bird_gray = np.sum(I_bird, axis=2) / 3\n",
    "I_bird_mask = treshold_mask(I_bird_gray, otsu_treshold(I_bird_gray, 256))\n",
    "plt.title(\"Exercise 3, task (b): initial mask\")\n",
    "plt.imshow(I_bird_mask, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "I_bird_mask = closing_ellipse(I_bird_mask, 24, 24)\n",
    "plt.title(\"Exercise 3, task (b): after closings ellipse (n1 = n2 = 24)\")\n",
    "plt.imshow(I_bird_mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task (c) and (d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is the background included in the mask and not the object? How would you fix that in general? (just inverting the mask if necessary doesn’t count)\n",
    "The question seems to be asking: how would you automatically determine if the image needs to be inverted?\n",
    "There are more ways to go about this.\n",
    "First idea: foreground is generally smaller than the background. Simply checking the initial_foreground-to-initial_background ratio would give us the answer. This fails when we are, for example, shooting our foreground from up close where it takes up most of the image.\n",
    "Second idea: Check the values in the corners of the image. Generally the corners will be filled with the background. This doesn't help us, however, when the exactly two corners have the initial_foreground in them. It also fails when we, for example, have many objects in our foreground and they happen to be located in the corners.\n",
    "Third (winning) idea: The background is generally less connected than the foreground. The foreground might have many objects in it, but those each of these object will roughly be a connected component. The background, however, will generally be one big connected component spanning all over the image. We could try doing this:\n",
    "- run the connected-components algorithm on the initial foreground. Calculate the variance for each component individually (find it's centre and sum the squares of distances from that centre for each pixel in that connected component). Sum up all these variances.\n",
    "- invert the foreground and background and perform the same task.\n",
    "The solution with the least variance should be the foreground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def invert_mask(I_mask):\n",
    "    new_mask = 1-I_mask[:,:]\n",
    "    return new_mask\n",
    "\n",
    "def immask(I_three_channel, I_mask):\n",
    "    \n",
    "    new_shape = (I_mask.shape[0], I_mask.shape[1], 3)\n",
    "    I_3chan_mask = np.zeros(new_shape)\n",
    "    \n",
    "    for i in range(3):\n",
    "        I_3chan_mask[:,:,i] = I_mask[:,:]\n",
    "\n",
    "    I_masked_three_channel = I_three_channel * I_3chan_mask\n",
    "    return I_masked_three_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_eagle = imread(\".\\\\images\\\\eagle.jpg\")\n",
    "I_eagle_gray = np.sum(I_eagle, axis=2) / 3\n",
    "I_eagle_mask = treshold_mask(I_eagle_gray, otsu_treshold(I_eagle_gray, 256))\n",
    "\n",
    "I_eagle_mask = invert_mask(I_eagle_mask)\n",
    "I_eagle_masked = immask(I_eagle, I_eagle_mask)\n",
    "plt.title(\"Excercise 3, task (c) and (d)\")\n",
    "plt.imshow(I_eagle_masked)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def immask_white_background(I_three_channel, I_mask):\n",
    "    \n",
    "    new_shape = (I_mask.shape[0], I_mask.shape[1], 3)\n",
    "    I_3chan_mask = np.zeros(new_shape)\n",
    "    \n",
    "    for i in range(3):\n",
    "        I_3chan_mask[:,:,i] = I_mask[:,:]\n",
    "    \n",
    "    white_background_mask = np.ones(new_shape) - I_3chan_mask\n",
    "\n",
    "    I_masked_three_channel = I_three_channel * I_3chan_mask\n",
    "    I_masked_three_channel = I_masked_three_channel + white_background_mask\n",
    "    \n",
    "    return I_masked_three_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_coins = imread(\".\\\\images\\\\coins.jpg\")\n",
    "I_coins_gray = np.sum(I_coins, axis=2) / 3\n",
    "I_coins_mask = treshold_mask(I_coins_gray, otsu_treshold(I_coins_gray, 256))\n",
    "I_opened = opening(I_coins_mask, 7)\n",
    "I_opened = opening(I_opened, 9)\n",
    "\n",
    "I_opened = invert_mask(I_opened)\n",
    "\n",
    "I_opened = I_opened.astype('uint8')\n",
    "returned_data = cv2.connectedComponentsWithStats(I_opened)\n",
    "num_of_components = returned_data[0]\n",
    "labels = returned_data[1]\n",
    "stats = returned_data[2]\n",
    "centroids = returned_data[3]\n",
    "\n",
    "for i in range (1, num_of_components):\n",
    "    if(stats[(i, cv2.CC_STAT_AREA)] > 700):\n",
    "        ix_left = stats[(i, cv2.CC_STAT_LEFT)]\n",
    "        ix_right = stats[(i, cv2.CC_STAT_LEFT)] + stats[(i, cv2.CC_STAT_WIDTH)]\n",
    "        ix_top = stats[(i, cv2.CC_STAT_TOP)]\n",
    "        ix_bottom = stats[(i, cv2.CC_STAT_TOP)] + stats[(i, cv2.CC_STAT_HEIGHT)]\n",
    "        \n",
    "        # tole pa ne dela for some reason:\n",
    "        # I_opened[ix_top:ix_bottom][ix_left:ix_right] = 0\n",
    "        I_opened[ix_top:ix_bottom, ix_left:ix_right] = 0\n",
    "\n",
    "        \"\"\"\n",
    "        stats so oblike (label, COLUMN)\n",
    "        Column vrednosti so:\n",
    "        CC_STAT_LEFT Python: cv.CC_STAT_LEFT\n",
    "        The leftmost (x) coordinate which is the inclusive start of the bounding box in the horizontal direction.\n",
    "        CC_STAT_TOP Python: cv.CC_STAT_TOP\n",
    "        CC_STAT_WIDTH \n",
    "        Python: cv.CC_STAT_WIDTH\n",
    "        The horizontal size of the bounding box.\n",
    "        CC_STAT_HEIGHT \n",
    "        Python: cv.CC_STAT_HEIGHT\n",
    "        The vertical size of the bounding box.\n",
    "        CC_STAT_AREA The total area (in pixels)\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "imshow(I_opened, \"Excercise 3, task (e): mask\")\n",
    "\n",
    "I_small_coins = immask_white_background(I_coins, I_opened)\n",
    "imshow(I_small_coins, \"Excercise 3, task (e): new image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
