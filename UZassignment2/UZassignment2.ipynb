{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import a2_utils as a2u\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1, task b\n",
    "Question: Can you recognize the shape of the kernel? What is the sum of the elements in the kernel? How does the kernel affect the signal?\n",
    "This is a gaussian kernel. The sum is approximately 1. The kernel smoothenes the signal through gaussian filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_on_slice(signal_1: np.array, signal_2: np.array):\n",
    "    correlation = np.sum(signal_1 * signal_2)\n",
    "    return correlation\n",
    "\n",
    "test_signal_1 = np.array([2, 3, 4])\n",
    "test_signal_2 = np.array([7, 5, 2])\n",
    "test_correlation = correlation_on_slice(test_signal_1, test_signal_2)\n",
    "print(\"correlation_on_slice test. Should be 37: \" + str(test_correlation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_convolution(signal_1D: np.array, kernel: np.array):\n",
    "    N = (kernel.size - 1) / 2\n",
    "    reversed_kernel = np.flip(kernel)\n",
    "\n",
    "    resulting_signal_length = int(signal_1D.size - 2*N)\n",
    "\n",
    "    resulting_signal = np.zeros(resulting_signal_length)\n",
    "    for i in range(resulting_signal_length):\n",
    "        resulting_signal[i] = correlation_on_slice(signal_1D[i:(i+kernel.size)], reversed_kernel)\n",
    "    \n",
    "    return resulting_signal\n",
    "\n",
    "test_signal = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "kernel = np.array([2, 0, 1])\n",
    "test_resulting_signal = simple_convolution(test_signal, kernel)\n",
    "print(\"simple_convolution test. Should be: [4, 7, 10, 13, 16, 19, 22, 25]\")\n",
    "print(test_resulting_signal)\n",
    "\n",
    "\n",
    "signal = a2u.read_data(\"signal.txt\")\n",
    "kernel = a2u.read_data(\"kernel.txt\")\n",
    "plt.plot(kernel)\n",
    "plt.show()\n",
    "print(np.sum(kernel))\n",
    "convolved_signal = simple_convolution(signal, kernel)\n",
    "cv2_convolution = cv2.filter2D(src=signal, ddepth=-1, kernel=kernel)\n",
    "\n",
    "\n",
    "plt.plot(signal, label=\"signal\")\n",
    "plt.plot(kernel, label=\"kernel\")\n",
    "plt.plot(convolved_signal, label=\"simple_convolution\")\n",
    "plt.plot(cv2_convolution, label=\"cv2.filter2D\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1, task c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_padded_convolution(signal_1D: np.array, kernel: np.array):\n",
    "    N = int((kernel.size - 1) / 2)\n",
    "    \n",
    "    signal_1D_padded = signal_1D.copy()\n",
    "    mirror_signal_1D = np.flip(signal_1D)\n",
    "    signal_1D_padded = np.insert(signal_1D_padded, 0, mirror_signal_1D[-N:])\n",
    "    signal_1D_padded = np.append(signal_1D_padded, mirror_signal_1D[0:N])\n",
    "    test_dimensions_check = signal_1D_padded.size == (signal_1D.size + 2*N)\n",
    "    # print(\"mirror_padded_convolution dimensions check. Should be True:\" + str(test_dimensions_check))\n",
    "    \n",
    "    reversed_kernel = np.flip(kernel)\n",
    "\n",
    "    resulting_signal = np.zeros(signal_1D.size)\n",
    "    for i in range(resulting_signal.size):\n",
    "        resulting_signal[i] = correlation_on_slice(signal_1D_padded[i:(i+kernel.size)], reversed_kernel)\n",
    "    \n",
    "    return resulting_signal\n",
    "\n",
    "\n",
    "signal = a2u.read_data(\"signal.txt\")\n",
    "kernel = a2u.read_data(\"kernel.txt\")\n",
    "convolved_signal = mirror_padded_convolution(signal, kernel)\n",
    "cv2_convolution = cv2.filter2D(src=signal, ddepth=-1, kernel=kernel)\n",
    "\n",
    "\n",
    "plt.plot(signal, label=\"signal\")\n",
    "plt.plot(kernel, label=\"kernel\")\n",
    "plt.plot(convolved_signal, label=\"mirror_padded_convolution\")\n",
    "plt.plot(cv2_convolution, label=\"cv2.filter2D\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1, task d\n",
    "Question: The figure below shows two kernels (a) and (b) as well as signal (c). Sketch (do not focus on exact proportions of your drawing, but rather on the understanding\n",
    "of what you are doing) the resulting convolved signal of the given input signal and each kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gauss(sigma: float):\n",
    "    side_width = int(math.ceil(3*sigma))\n",
    "    kernel_size = int(2 * side_width +1)\n",
    "    kernel_x_values = np.array(range(-side_width, side_width+1))\n",
    "    coef = 1 / (sigma * math.sqrt(2*math.pi))\n",
    "    kernel =  coef * np.exp( -(kernel_x_values ** 2) / (2* (sigma**2)) )\n",
    "    kernel /= np.sum(kernel)\n",
    "    return kernel, kernel_x_values\n",
    "\n",
    "sigmas = [0.5, 1, 2, 3, 4]\n",
    "for i in sigmas:\n",
    "    kernel, kernel_x_values = gauss(i)\n",
    "    plt.plot(kernel_x_values, kernel)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1, task (e)\n",
    "\n",
    "k_2 is probably given wrong. It should sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "k_1, _ = gauss(2)\n",
    "k_2 = np.array([0.1, 0.6, 0.4])\n",
    "signal = a2u.read_data(\"signal.txt\")\n",
    "\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.plot(signal)\n",
    "\n",
    "plt.subplot(1, 4, 2)\n",
    "preconvolved = mirror_padded_convolution(signal, k_1)\n",
    "convolved_signal = mirror_padded_convolution(preconvolved, k_2)\n",
    "plt.plot(convolved_signal)\n",
    "\n",
    "plt.subplot(1, 4, 3)\n",
    "preconvolved = mirror_padded_convolution(signal, k_2)\n",
    "convolved_signal = mirror_padded_convolution(preconvolved, k_1)\n",
    "plt.plot(convolved_signal)\n",
    "\n",
    "plt.subplot(1, 4, 4)\n",
    "k_3 = mirror_padded_convolution(k_1, k_2)\n",
    "convolved_signal = mirror_padded_convolution(signal, k_3)\n",
    "plt.plot(convolved_signal)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2, task (a)\n",
    "Question: Which noise is better removed using the Gaussian filter? \\\n",
    "Gaussian noise is better removed. Salt and pepper isn't really reoved, the blur just makes it less prominent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussfilter(img, sigma):\n",
    "    kernel_1D, _ = gauss(sigma)\n",
    "    kernel_1D = kernel_1D.reshape((1, kernel_1D.size))\n",
    "    # print(kernel_1D.shape)\n",
    "    # print(kernel_1D.T)\n",
    "\n",
    "    kernel_2D = kernel_1D.T * kernel_1D\n",
    "    kernel_2D = kernel_2D / np.sum(kernel_2D)\n",
    "    # print(kernel_2D)\n",
    "    convolved_img = cv2.filter2D(src=img, ddepth=-1, kernel=kernel_2D)\n",
    "    return convolved_img\n",
    "\n",
    "# 1,5 so oni uporabili\n",
    "sigma = 2\n",
    "\n",
    "lena_img = plt.imread(\".\\\\images\\\\lena.png\")\n",
    "lena_img = lena_img.astype(np.float64)\n",
    "lena_gray = np.sum(lena_img, axis=2) / 3\n",
    "# print(lena_gray.max())\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Gray image\")\n",
    "plt.imshow(lena_gray, cmap='gray')\n",
    "\n",
    "lena_gaussian_filter = gaussfilter(lena_gray, sigma)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Gaussian blur\")\n",
    "plt.imshow(lena_gaussian_filter, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "lena_gaussian_noise = a2u.gauss_noise(lena_gray)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Gauss noise\")\n",
    "plt.imshow(lena_gaussian_noise, cmap='gray')\n",
    "\n",
    "\n",
    "lena_G_N_filtered = gaussfilter(lena_gaussian_noise, sigma)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Gauss noise, gauss filter\")\n",
    "plt.imshow(lena_G_N_filtered, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "lena_SAP_noise = a2u.sp_noise(lena_gray)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"SP noise\")\n",
    "plt.imshow(lena_SAP_noise, cmap='gray')\n",
    "\n",
    "lena_SAP_N_filtered = gaussfilter(lena_SAP_noise, sigma)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"SP noise, gauss filter\")\n",
    "plt.imshow(lena_SAP_N_filtered, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2, task b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(img, kernel_width_and_heigth, difference_constant=1):\n",
    "    sharpening_kernel = difference_constant * (-1/(kernel_width_and_heigth**2)) * np.ones((kernel_width_and_heigth,kernel_width_and_heigth))\n",
    "    centre_element_ix = int((kernel_width_and_heigth-1)/2)\n",
    "    sharpening_kernel[centre_element_ix, centre_element_ix] += 1 + difference_constant\n",
    "    print(sharpening_kernel)\n",
    "\n",
    "    convolved_img = cv2.filter2D(src=img, ddepth=-1, kernel=sharpening_kernel)\n",
    "    return convolved_img\n",
    "\n",
    "museum_img = plt.imread(\".\\\\images\\\\museum.jpg\")\n",
    "museum_img = museum_img.astype(np.float64) / 255\n",
    "museum_gray = np.sum(museum_img, axis=2) / 3\n",
    "plt.imshow(museum_gray, cmap='gray')\n",
    "plt.title(\"Gray image\")\n",
    "plt.show()\n",
    "\n",
    "museum_sharpened = sharpen(museum_gray, 5)\n",
    "print(museum_gray.min())\n",
    "print(museum_gray.max())\n",
    "\n",
    "plt.imshow(museum_sharpened, cmap='gray', vmin=0, vmax=1)\n",
    "plt.title(\"Sharpened\")\n",
    "plt.show()\n",
    "\n",
    "print(np.mean(museum_gray))\n",
    "print(np.mean(museum_sharpened))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2, task c\n",
    "Question: Which filter performs better at this specific task? In comparison to Gaussian filter that can be applied multiple times in any order, does the order matter in case of median filter? What is the name of filters like this? \\\n",
    "The median filter performs better at this task.\\\n",
    "The order of operations does matter for the median filter. \\\n",
    "Such filters are called non-linear. \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_noise_1D(signal, percent=.2):\n",
    "\tres = signal.copy()\n",
    "\tres[np.random.rand(signal.size) < percent / 2] = 1\n",
    "\tres[np.random.rand(signal.size) < percent / 2] = 0\n",
    "\treturn res\n",
    "\n",
    "def simple_median(signal: np.array, width):\n",
    "    N = int((width-1)/2)\n",
    "    return_array = np.zeros(signal.size)\n",
    "\n",
    "    for i in range(return_array.size):\n",
    "        \n",
    "        left_ix = i - N\n",
    "        right_ix = i + N\n",
    "\n",
    "        if left_ix < 0:\n",
    "            left_ix = 0\n",
    "        if right_ix >= return_array.size:\n",
    "            right_ix = return_array.size - 1\n",
    "        \n",
    "        return_array[i] = np.median(signal[left_ix : right_ix+1])\n",
    "    \n",
    "    return return_array\n",
    "\n",
    "\n",
    "\n",
    "simple_signal = np.zeros(40)\n",
    "simple_signal[10:21] = 1\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"Basic signal\")\n",
    "plt.plot(simple_signal)\n",
    "\n",
    "simple_signal_SAP_corrupted = sp_noise_1D(simple_signal)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"SP noised\")\n",
    "plt.plot(simple_signal_SAP_corrupted)\n",
    "plt.show()\n",
    "\n",
    "simple_signal_SAP_simple_median = simple_median(simple_signal_SAP_corrupted, 3)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title(\"SP noised, median filter\")\n",
    "plt.plot(simple_signal_SAP_simple_median)\n",
    "\n",
    "simple_signal_SAP_gauss_filter = gaussfilter(simple_signal_SAP_corrupted, 1)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title(\"SP noised, gauss filter\")\n",
    "plt.plot(simple_signal_SAP_gauss_filter)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2, task d\n",
    "Question: What is the computational complexity of the Gaussian filter operation? How about the median filter? What does it depend on? Describe the computational complexity using the O(.) notation (you can assume n*log(n) complexity for sorting).\n",
    "\n",
    "With an n1 x n1 kernel and an m x n image:\n",
    "Gaussian filter performs n1 x n1 operations m x n times. So it has O(m * n * n1^2)\n",
    "Median filter performs a sort on n1 * n1 operands m x n times. This makes it O(m * n * n1^2 * log(n1^2)) = O(m * n * n1^2 * 2 * log(n1^2)) = O(m * n * n1^2 * log(n1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_2D_filter(img, width):\n",
    "    N = int((width-1)/2)\n",
    "    return_array = np.zeros(img.shape)\n",
    "\n",
    "    for i in range(return_array.shape[0]):\n",
    "        for j in range(return_array.shape[1]):\n",
    "            \n",
    "            upper_ix = i - N\n",
    "            lower_ix = i + N\n",
    "\n",
    "            if upper_ix < 0:\n",
    "                upper_ix = 0\n",
    "            if lower_ix >= return_array.shape[0]:\n",
    "                lower_ix = return_array.shape[0] - 1\n",
    "\n",
    "            left_ix = j - N\n",
    "            right_ix = j + N\n",
    "\n",
    "            if left_ix < 0:\n",
    "                left_ix = 0\n",
    "            if right_ix >= return_array.shape[1]:\n",
    "                right_ix = return_array.shape[1] - 1\n",
    "            \n",
    "            return_array[i,j] = np.median(img[upper_ix : lower_ix + 1, left_ix : right_ix+1])\n",
    "    \n",
    "    return return_array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gaussian_2D_kernel(sigma):\n",
    "    kernel_1D, _ = gauss(sigma)\n",
    "    kernel_1D = np.reshape(kernel_1D, (1, kernel_1D.size))\n",
    "    kernel_2D = kernel_1D.T * kernel_1D\n",
    "    kernel_2D = kernel_2D / np.sum(kernel_2D)\n",
    "\n",
    "    # print(kernel_1D)\n",
    "    # print(kernel_2D)\n",
    "    # print(\"\\n\\n\\n\")\n",
    "    return kernel_2D\n",
    "\n",
    "def gaussian_2D_filter(img, sigma=3):\n",
    "    \n",
    "    kernel_2D = gaussian_2D_kernel(sigma)\n",
    "\n",
    "    convolved_img = cv2.filter2D(src=img, ddepth=-1, kernel=kernel_2D)\n",
    "    return convolved_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def gauss_with_width(width, sigma=-1):\n",
    "        \n",
    "#     if sigma == -1:\n",
    "#         # side_width = int(math.ceil(3*sigma))\n",
    "#         sigma = width / 3\n",
    "    \n",
    "#     side_width = int((width - 1) / 2)\n",
    "#     kernel_x_values = np.array(range(-side_width, side_width+1))\n",
    "#     coef = 1 / (sigma * math.sqrt(2*math.pi))\n",
    "#     kernel =  coef * np.exp( -(kernel_x_values ** 2) / (2* (sigma**2)) )\n",
    "    \n",
    "#     kernel /= np.sum(kernel)\n",
    "#     return kernel, kernel_x_values\n",
    "\n",
    "# def gaussian_with_width_2D_kernel(width, sigma=-1):\n",
    "#     kernel_1D, _ = gauss_with_width(width, sigma)\n",
    "#     kernel_1D = np.reshape(kernel_1D, (1, kernel_1D.size))\n",
    "#     kernel_2D = kernel_1D.T * kernel_1D\n",
    "#     kernel_2D = kernel_2D / np.sum(kernel_2D)\n",
    "\n",
    "#     # print(kernel_1D)\n",
    "#     # print(kernel_2D)\n",
    "#     # print(\"\\n\\n\\n\")\n",
    "#     return kernel_2D\n",
    "\n",
    "# def gaussian_with_width_2D_filter(img, width, sigma=-1):\n",
    "    \n",
    "#     kernel_2D = gaussian_with_width_2D_kernel(width, sigma)\n",
    "\n",
    "#     convolved_img = cv2.filter2D(src=img, ddepth=-1, kernel=kernel_2D)\n",
    "#     return convolved_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lena_img = plt.imread(\".\\\\images\\\\lena.png\")\n",
    "lena_img = lena_img.astype(np.float64)\n",
    "lena_gray = np.sum(lena_img, axis=2) / 3\n",
    "\n",
    "corrupt_prob = 0.4\n",
    "lena_SAP_noise = a2u.sp_noise(lena_gray, corrupt_prob)\n",
    "plt.title(\"SAP\")\n",
    "plt.imshow(lena_SAP_noise, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for sigma in range(1, 7, 2):\n",
    "\n",
    "    lena_SAP_N_gauss_filtered = gaussian_2D_filter(lena_SAP_noise, sigma)\n",
    "    plt.imshow(lena_SAP_N_gauss_filtered, cmap='gray')\n",
    "    plt.title(\"SAP, gauss filtered. Sigma: \" + str(sigma))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "width = 5\n",
    "lena_SAP_N_median_filtered = median_2D_filter(lena_SAP_noise, width)\n",
    "plt.title(\"SAP, median filtered\")\n",
    "plt.imshow(lena_SAP_N_median_filtered, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lena_gauss_noise = a2u.gauss_noise(lena_gray)\n",
    "plt.title(\"gauss noise\")\n",
    "plt.imshow(lena_gauss_noise, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for sigma in range(1, 7, 2):\n",
    "\n",
    "    lena_gauss_noise_gauss_filtered = gaussian_2D_filter(lena_gauss_noise, sigma)\n",
    "    plt.imshow(lena_gauss_noise_gauss_filtered, cmap='gray')\n",
    "    plt.title(\"Gauss noise, gauss filtered. Sigma: \" + str(sigma))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "width = 5\n",
    "lena_gauss_noise_median_filtered = median_2D_filter(lena_gauss_noise, width)\n",
    "plt.title(\"Gauss, median filtered\")\n",
    "plt.imshow(lena_gauss_noise_median_filtered, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Compare gaussian and median:\n",
    "\n",
    "# for corrupt_prob in np.arange(0.0, 1, 0.3):\n",
    "#     lena_SAP_noise = a2u.sp_noise(lena_gray, corrupt_prob)\n",
    "#     plt.imshow(lena_SAP_noise, cmap='gray')\n",
    "#     plt.show()\n",
    "\n",
    "#     for width in range(3, 10, 3):\n",
    "\n",
    "#         lena_SAP_N_median_filtered = median_2D_filter(lena_SAP_noise, width)\n",
    "#         plt.subplot(1, 2, 1)\n",
    "#         plt.imshow(lena_SAP_N_median_filtered, cmap='gray')\n",
    "        \n",
    "#         lena_SAP_N_gauss_filtered = gaussian_2D_filter(lena_SAP_noise, width)\n",
    "#         plt.subplot(1, 2, 2)\n",
    "#         plt.imshow(lena_SAP_N_gauss_filtered, cmap='gray')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2, task e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def laplacian_2D_filter(img, sigma):\n",
    "\n",
    "    gaussian_kernel = gaussian_2D_kernel(sigma)\n",
    "\n",
    "    # print(gaussian_kernel.shape)\n",
    "\n",
    "    laplacian_kernel = np.zeros(gaussian_kernel.shape)\n",
    "    middle_ix = int((gaussian_kernel.shape[0]-1)/2)\n",
    "    laplacian_kernel[middle_ix, middle_ix] = 1 # has to be two, so that when we subtract the gaussian it adds up to 1.\n",
    "\n",
    "    laplacian_kernel = laplacian_kernel - gaussian_kernel\n",
    "\n",
    "    # print(laplacian_kernel, gaussian_kernel)\n",
    "\n",
    "    convolved_img = cv2.filter2D(src=img, ddepth=-1, kernel=laplacian_kernel)\n",
    "    return convolved_img\n",
    "\n",
    "\n",
    "# def laplacian_with_width_2D_filter(img, width, sigma):\n",
    "#     laplacian_kernel = np.zeros((width, width))\n",
    "#     middle_ix = int((width-1)/2)\n",
    "#     laplacian_kernel[middle_ix, middle_ix] = 2 # has to be two, so that when we subtract the gaussian it adds up to 1.\n",
    "\n",
    "#     gaussian_kernel = gaussian_with_width_2D_kernel(width, sigma)\n",
    "\n",
    "#     laplacian_kernel = laplacian_kernel - gaussian_kernel\n",
    "\n",
    "#     # print(laplacian_kernel, gaussian_kernel)\n",
    "\n",
    "#     convolved_img = cv2.filter2D(src=img, ddepth=-1, kernel=laplacian_kernel)\n",
    "#     return convolved_img\n",
    "\n",
    "lincoln_img = plt.imread(\".\\\\images\\\\lincoln.jpg\")\n",
    "lincoln_img = lincoln_img.astype(np.float64)\n",
    "lincoln_gray = np.sum(lincoln_img, axis=2) / 3\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(lincoln_gray, cmap='gray')\n",
    "\n",
    "obama_img = plt.imread(\".\\\\images\\\\obama.jpg\")\n",
    "obama_img = obama_img.astype(np.float64)\n",
    "obama_gray = np.sum(obama_img, axis=2) / 3\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(obama_gray, cmap='gray')\n",
    "print(\"Basic gray images:\")\n",
    "plt.show()\n",
    "\n",
    "sigma = 10\n",
    "obama_gauss = gaussian_2D_filter(obama_gray, sigma)\n",
    "lincoln_gauss = gaussian_2D_filter(lincoln_gray, sigma)\n",
    "\n",
    "for sigma in range(10, 11, 2):\n",
    "    \n",
    "    obama_laplace = laplacian_2D_filter(obama_gray, sigma)\n",
    "    lincoln_laplace = laplacian_2D_filter(lincoln_gray, sigma)\n",
    "    \n",
    "    print(\"Sigma: \" + str(sigma) + \". Filtered images and their mergings:\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(obama_gauss, cmap=\"gray\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(obama_laplace, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(lincoln_gauss, cmap=\"gray\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(lincoln_laplace, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    for base_coef in np.arange(0.5, 0.6, 0.1):\n",
    "        # print(\"Base coef:\" + str(base_coef))\n",
    "\n",
    "        obama_is_base = base_coef * obama_gauss + (1-base_coef) * lincoln_laplace\n",
    "        lincoln_is_base = base_coef * lincoln_gauss + (1-base_coef) * obama_laplace\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(obama_is_base, cmap=\"gray\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(lincoln_is_base, cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myhist3(img, num_of_bins):\n",
    "    histogram = np.zeros((num_of_bins, num_of_bins, num_of_bins))\n",
    "    divider = 1 / num_of_bins\n",
    "\n",
    "    for y in range(img.shape[0]):\n",
    "        for x in range(img.shape[1]):\n",
    "            R = int(math.floor(img[y][x][0] / divider))\n",
    "            G = int(math.floor(img[y][x][1] / divider))\n",
    "            B = int(math.floor(img[y][x][2] / divider))\n",
    "\n",
    "            histogram[R][G][B] += 1\n",
    "    \n",
    "    histogram = histogram / histogram.sum()\n",
    "\n",
    "    return histogram\n",
    "\n",
    "def red_in_histogram(histogram):\n",
    "    red_histogram = histogram.sum((1, 2))\n",
    "    return red_histogram\n",
    "\n",
    "def green_in_histogram(histogram):\n",
    "    red_histogram = histogram.sum((0, 2))\n",
    "    return red_histogram\n",
    "\n",
    "def blue_in_histogram(histogram):\n",
    "    red_histogram = histogram.sum((0, 1))\n",
    "    return red_histogram\n",
    "\n",
    "def print_colours_summed_from_3D_hist(hist):\n",
    "        print(\"R: \" + str(red_in_histogram(hist)))\n",
    "        print(\"G: \" + str(green_in_histogram(hist)))\n",
    "        print(\"B: \" + str(blue_in_histogram(hist)))\n",
    "\n",
    "\n",
    "\n",
    "num_of_bins = 3\n",
    "\n",
    "tomato_img = plt.imread(\".\\\\dataset\\\\object_04_2.png\")\n",
    "# print(tomato_img.max())\n",
    "tomato_hist = myhist3(tomato_img, num_of_bins)\n",
    "# print(tomato_hist)\n",
    "\n",
    "frog_img = plt.imread(\".\\\\dataset\\\\object_28_4.png\")\n",
    "frog_hist = myhist3(frog_img, num_of_bins)\n",
    "# print(frog_hist)\n",
    "\n",
    "print_colours_summed_from_3D_hist(tomato_hist)\n",
    "print_colours_summed_from_3D_hist(frog_hist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_distance(hist1, hist2):\n",
    "    hist_diff = hist1 - hist2\n",
    "    hist_dist = math.sqrt(np.sum(hist_diff ** 2))\n",
    "    return hist_dist\n",
    "\n",
    "def chi_square_distance(hist1, hist2):\n",
    "    hist_dist_numerator = (hist1 - hist2) ** 2\n",
    "    hist_dist_denominator = hist1 + hist2 + 1e-10 * np.ones(hist1.shape)\n",
    "\n",
    "    hist_dist = 1/2 * np.sum(hist_dist_numerator / hist_dist_denominator)\n",
    "    return hist_dist\n",
    "\n",
    "def intersection_distance(hist1, hist2):\n",
    "    min_hist = np.minimum(hist1, hist2)\n",
    "    hist_dist = 1 - np.sum(min_hist)\n",
    "    return hist_dist\n",
    "\n",
    "def hellinger_distance(hist1, hist2):\n",
    "    hist_root_diff = hist1 ** (1/2) - hist2 ** (1/2)\n",
    "    hist_dist = (1/2 * np.sum(hist_root_diff ** 2)) ** (1/2)\n",
    "    return hist_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task c\n",
    "Question: Which image (object_02_1.png or object_03_1.png) is more similar to image object_01_1.png considering the L2 distance? How about the other three distances? We can see that all three histograms contain a strongly expressed component\n",
    "(one bin has a much higher value than the others). Which color does this bin represent?\n",
    "\n",
    "With all distances object_03_1.png is more similar to object_01_1.png than object_02_1.png.\n",
    "\n",
    "This bin represents the collor black. This is the colour of the background, which has all three values at zero.\n",
    "We used np.reshape(-1), which reshapes in a C-like ordering. It therefore starts with all three components being zero and first changes along the last component (blue in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_bins = 8\n",
    "\n",
    "img1 = plt.imread(\".\\\\dataset\\\\object_01_1.png\")\n",
    "img2 = plt.imread(\".\\\\dataset\\\\object_02_1.png\")\n",
    "img3 = plt.imread(\".\\\\dataset\\\\object_03_1.png\")\n",
    "\n",
    "hist1 = myhist3(img1, num_of_bins).reshape(-1)\n",
    "hist2 = myhist3(img2, num_of_bins).reshape(-1)\n",
    "hist3 = myhist3(img3, num_of_bins).reshape(-1)\n",
    "\n",
    "images = [img1, img2, img3]\n",
    "histograms = [hist1, hist2, hist3]\n",
    "for i in range(1, 4):\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.imshow(images[i-1])\n",
    "for i in range(1, 4):\n",
    "    plt.subplot(2, 3, i+3)\n",
    "    plt.title(\"L2: \" + \"{:.2f}\".format(L2_distance(histograms[0], histograms[i-1])))\n",
    "    plt.plot(histograms[i-1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"chi2: \" + \"{:.2f}\".format(chi_square_distance(histograms[0], histograms[i])))\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Inters: \" + \"{:.2f}\".format(intersection_distance(histograms[0], histograms[i])))\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"hell: \" + \"{:.2f}\".format(hellinger_distance(histograms[0], histograms[i])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task d\n",
    "\n",
    "Hellinger distance performed best in terms of absolute distance between the sought out object and the next closest one (0.16 and 0.36; so the difference is 0.20). This seems to make it the best distance for this application.\n",
    "\n",
    "Chi-squared distance performed best in terms of relative distance between the sought out object and the next closest one (0.04 and 0.16; so the difference is x4)\n",
    "\n",
    "\n",
    "The retrieved sequence of images does change. It only changes in the images of the wrong objects.\n",
    "The distance seem to increse.\n",
    "\n",
    "The excecution time is slightly affected by the number of bins. The calculation of distances becomes more time consuming. But since this operation isn't the main contributor to the excecution time, the overall time doesn't change much.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_bins = 8\n",
    "\n",
    "base_path = \".\\\\dataset\"\n",
    "dir_list = os.listdir(base_path)\n",
    "# print(dir_list)\n",
    "\n",
    "images = []\n",
    "for name in dir_list:\n",
    "    read_image = plt.imread(base_path + \"\\\\\" + name)\n",
    "    images.append(read_image)\n",
    "\n",
    "\n",
    "hists_3D = []\n",
    "for img in images:\n",
    "    hists_3D.append(myhist3(img, num_of_bins))\n",
    "\n",
    "hists_1D_C_ordering = []\n",
    "for hist in hists_3D:\n",
    "    hists_1D_C_ordering.append(hist.reshape(-1))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_element_from_lists(list_of_lists, ix):\n",
    "    for given_list in list_of_lists:\n",
    "        del given_list[ix]\n",
    "\n",
    "\n",
    "list_of_lists = [dir_list, images, hists_3D, hists_1D_C_ordering]\n",
    "chosen_ix = 19\n",
    "\n",
    "chosen_img = images[chosen_ix]\n",
    "chosen_3D_histogram = hists_3D[chosen_ix]\n",
    "chosen_1D_histogram = hists_1D_C_ordering[chosen_ix]\n",
    "\n",
    "plt.imshow(images[chosen_ix])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir_list[chosen_ix-1 : chosen_ix+2])\n",
    "remove_element_from_lists(list_of_lists, chosen_ix)\n",
    "print(dir_list[chosen_ix-1 : chosen_ix+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "L2_distances_with_ixs = []\n",
    "chi_square_distances_with_ixs = []\n",
    "intersection_distances_with_ixs = []\n",
    "hellinger_distances_with_ixs = []\n",
    "\n",
    "for ix in range(len(hists_1D_C_ordering)):\n",
    "    hist = hists_1D_C_ordering[ix]\n",
    "    L2_distances_with_ixs.append((L2_distance(hist, chosen_1D_histogram), ix))\n",
    "    chi_square_distances_with_ixs.append((chi_square_distance(hist, chosen_1D_histogram), ix))\n",
    "    intersection_distances_with_ixs.append((intersection_distance(hist, chosen_1D_histogram), ix))\n",
    "    hellinger_distances_with_ixs.append((hellinger_distance(hist, chosen_1D_histogram), ix))\n",
    "\n",
    "distances_lists = [L2_distances_with_ixs, chi_square_distances_with_ixs, intersection_distances_with_ixs, hellinger_distances_with_ixs]\n",
    "sorted_distances_lists = []\n",
    "for given_list in distances_lists:\n",
    "    sorted_distances_lists.append(sorted(given_list)) #key=lambda pair: pair[0]\n",
    "\n",
    "# distance_short_names = [\"L2\", \"chi\", \"inter\", \"hell\"]\n",
    "for sorted_dist_list in sorted_distances_lists:\n",
    "    plt.subplot(2, 6, 1)\n",
    "    plt.title(dir_list[chosen_ix])\n",
    "    plt.imshow(chosen_img)\n",
    "    plt.subplot(2, 6, 7)\n",
    "    plt.plot(chosen_1D_histogram)\n",
    "\n",
    "    for i in range(5):\n",
    "        distance, ix = sorted_dist_list[i]\n",
    "        plt.subplot(2, 6, 2+i)\n",
    "        plt.title(dir_list[ix])\n",
    "        plt.imshow(images[ix])\n",
    "        plt.subplot(2, 6, 8+i)\n",
    "        plt.title(\"{:.2f}\".format(distance))\n",
    "        plt.plot(hists_1D_C_ordering[ix])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3, task e\n",
    "This improves the result substantially for all distances. This can also be seen in the bar plots of the histograms, because the black pixels play a majorly reduced value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(distances_lists)):\n",
    "    data = [datapoint[0] for datapoint in distances_lists[i]]\n",
    "    data_sorted = [datapoint[0] for datapoint in sorted_distances_lists[i]]\n",
    "    \n",
    "    best_ixs = [datapoint[1] for datapoint in sorted_distances_lists[i][0:5]]\n",
    "    best_datums = [datapoint[0] for datapoint in sorted_distances_lists[i][0:5]]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(data)\n",
    "    plt.scatter(best_ixs, best_datums, marker=\"o\", facecolors=\"none\", edgecolors=\"k\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(data_sorted)\n",
    "    plt.scatter(range(5), best_datums, marker=\"o\", facecolors=\"none\", edgecolors=\"k\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_frequency_histogram(list_of_histograms):\n",
    "    sum_hist = np.zeros(list_of_histograms[0].shape)\n",
    "    for hist in list_of_histograms:\n",
    "        sum_hist += hist\n",
    "    \n",
    "    average_hist = sum_hist / len(list_of_histograms)\n",
    "    return average_hist\n",
    "\n",
    "def exponential_weights_from_avg_freq_hist(avg_freq_hist, lam):\n",
    "    scaled = -lam * avg_freq_hist\n",
    "    # print(scaled)\n",
    "    weights = np.exp(scaled)\n",
    "    print(weights)\n",
    "    return weights\n",
    "\n",
    "average_frequency_hist = average_frequency_histogram(hists_3D)\n",
    "\n",
    "# lam = 20 kar dobro deluje\n",
    "lam = 100\n",
    "\n",
    "# print(average_frequency_hist)\n",
    "exp_weights = exponential_weights_from_avg_freq_hist(average_frequency_hist, lam)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def new_way(hists_3D, chosen_3D_histogram, exp_weights):\n",
    "    hists_3D = [ i * exp_weights for i in hists_3D]\n",
    "    hists_3D = [ i / np.sum(i) for i in hists_3D]\n",
    "    \n",
    "    chosen_3D_histogram = chosen_3D_histogram * exp_weights\n",
    "    chosen_3D_histogram = chosen_3D_histogram / np.sum(chosen_3D_histogram)\n",
    "    chosen_1D_histogram = chosen_3D_histogram.reshape(-1)\n",
    "\n",
    "    hists_1D_C_ordering = []\n",
    "    for hist in hists_3D:\n",
    "        hists_1D_C_ordering.append(hist.reshape(-1))\n",
    "\n",
    "\n",
    "    L2_distances_with_ixs = []\n",
    "    chi_square_distances_with_ixs = []\n",
    "    intersection_distances_with_ixs = []\n",
    "    hellinger_distances_with_ixs = []\n",
    "\n",
    "    for ix in range(len(hists_1D_C_ordering)):\n",
    "        hist = hists_1D_C_ordering[ix]\n",
    "        L2_distances_with_ixs.append((L2_distance(hist, chosen_1D_histogram), ix))\n",
    "        chi_square_distances_with_ixs.append((chi_square_distance(hist, chosen_1D_histogram), ix))\n",
    "        intersection_distances_with_ixs.append((intersection_distance(hist, chosen_1D_histogram), ix))\n",
    "        hellinger_distances_with_ixs.append((hellinger_distance(hist, chosen_1D_histogram), ix))\n",
    "\n",
    "    distances_lists = [L2_distances_with_ixs, chi_square_distances_with_ixs, intersection_distances_with_ixs, hellinger_distances_with_ixs]\n",
    "    sorted_distances_lists = []\n",
    "    for given_list in distances_lists:\n",
    "        sorted_distances_lists.append(sorted(given_list)) #key=lambda pair: pair[0]\n",
    "\n",
    "    # distance_short_names = [\"L2\", \"chi\", \"inter\", \"hell\"]\n",
    "    for sorted_dist_list in sorted_distances_lists:\n",
    "        plt.subplot(2, 6, 1)\n",
    "        plt.title(dir_list[chosen_ix])\n",
    "        plt.imshow(chosen_img)\n",
    "        plt.subplot(2, 6, 7)\n",
    "        plt.plot(chosen_1D_histogram)\n",
    "\n",
    "        for i in range(5):\n",
    "            distance, ix = sorted_dist_list[i]\n",
    "            plt.subplot(2, 6, 2+i)\n",
    "            plt.title(dir_list[ix])\n",
    "            plt.imshow(images[ix])\n",
    "            plt.subplot(2, 6, 8+i)\n",
    "            plt.title(\"{:.2f}\".format(distance))\n",
    "            plt.plot(hists_1D_C_ordering[ix])\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    for i in range(len(distances_lists)):\n",
    "        data = [datapoint[0] for datapoint in distances_lists[i]]\n",
    "        data_sorted = [datapoint[0] for datapoint in sorted_distances_lists[i]]\n",
    "        \n",
    "        best_ixs = [datapoint[1] for datapoint in sorted_distances_lists[i][0:5]]\n",
    "        best_datums = [datapoint[0] for datapoint in sorted_distances_lists[i][0:5]]\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(data)\n",
    "        plt.scatter(best_ixs, best_datums, marker=\"o\", facecolors=\"none\", edgecolors=\"k\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(data_sorted)\n",
    "        plt.scatter(range(5), best_datums, marker=\"o\", facecolors=\"none\", edgecolors=\"k\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "new_way(hists_3D, chosen_3D_histogram, exp_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
